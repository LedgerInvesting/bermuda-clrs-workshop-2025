{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bermuda Data Ingestion Workshop\n",
    "\n",
    "This notebook demonstrates various methods for ingesting data into Bermuda triangles. We'll cover multiple data formats and ingestion patterns commonly used in actuarial workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'plot_data_completeness' from 'bermuda.plot' (/Users/austinbrian/ldgr/bermuda-clrs-workshop-2025/.venv/lib/python3.11/site-packages/bermuda/plot.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbermuda\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtri\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ldgr/bermuda-clrs-workshop-2025/.venv/lib/python3.11/site-packages/bermuda/__init__.py:18\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatrix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     DisaggregatedValue,\n\u001b[32m     10\u001b[39m     Matrix,\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     RichMatrix,\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfactory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Triangle\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtriangle\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TriangleSlice\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdate_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ldgr/bermuda-clrs-workshop-2025/.venv/lib/python3.11/site-packages/bermuda/factory.py:41\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtriangle\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Triangle\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     27\u001b[39m     add_statics,\n\u001b[32m     28\u001b[39m     aggregate,\n\u001b[32m   (...)\u001b[39m\u001b[32m     39\u001b[39m     to_incremental,\n\u001b[32m     40\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     42\u001b[39m     plot_data_completeness,\n\u001b[32m     43\u001b[39m     plot_right_edge,\n\u001b[32m     44\u001b[39m     plot_heatmap,\n\u001b[32m     45\u001b[39m     plot_atas,\n\u001b[32m     46\u001b[39m     plot_growth_curve,\n\u001b[32m     47\u001b[39m     plot_mountain,\n\u001b[32m     48\u001b[39m     plot_sunset,\n\u001b[32m     49\u001b[39m     plot_ballistic,\n\u001b[32m     50\u001b[39m     plot_broom,\n\u001b[32m     51\u001b[39m     plot_drip,\n\u001b[32m     52\u001b[39m     plot_hose,\n\u001b[32m     53\u001b[39m     plot_histogram,\n\u001b[32m     54\u001b[39m )\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# utils\u001b[39;00m\n\u001b[32m     57\u001b[39m Triangle.aggregate = wraps(aggregate)(\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28mself\u001b[39m, *args, **kwargs: aggregate(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m     59\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'plot_data_completeness' from 'bermuda.plot' (/Users/austinbrian/ldgr/bermuda-clrs-workshop-2025/.venv/lib/python3.11/site-packages/bermuda/plot.py)"
     ]
    }
   ],
   "source": [
    "import bermuda as tri\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from datetime import date, datetime\n",
    "import io\n",
    "import os\n",
    "\n",
    "# Enable HTML rendering for Altair charts\n",
    "alt.renderers.enable(\"html\")\n",
    "\n",
    "print(f\"Bermuda version: {tri.__version__ if hasattr(tri, '__version__') else 'Unknown'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://aws:****@ledger-data-science-054739135172.d.codeartifact.us-east-2.amazonaws.com/pypi/python-ds/simple/\n",
      "Requirement already satisfied: bermuda-ledger in ./.venv/lib/python3.11/site-packages (2.1.15)\n",
      "Requirement already satisfied: altair in ./.venv/lib/python3.11/site-packages (from bermuda-ledger) (5.5.0)\n",
      "Requirement already satisfied: awswrangler in ./.venv/lib/python3.11/site-packages (from bermuda-ledger) (3.12.1)\n",
      "Requirement already satisfied: babel in ./.venv/lib/python3.11/site-packages (from bermuda-ledger) (2.17.0)\n",
      "Requirement already satisfied: numpy<2,>1.23.1 in ./.venv/lib/python3.11/site-packages (from bermuda-ledger) (1.26.4)\n",
      "Requirement already satisfied: pandas>1.4.1 in ./.venv/lib/python3.11/site-packages (from bermuda-ledger) (2.3.2)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.11/site-packages (from bermuda-ledger) (1.16.1)\n",
      "Requirement already satisfied: toolz in ./.venv/lib/python3.11/site-packages (from bermuda-ledger) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas>1.4.1->bermuda-ledger) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas>1.4.1->bermuda-ledger) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas>1.4.1->bermuda-ledger) (2025.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from altair->bermuda-ledger) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in ./.venv/lib/python3.11/site-packages (from altair->bermuda-ledger) (4.25.1)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in ./.venv/lib/python3.11/site-packages (from altair->bermuda-ledger) (2.2.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.11/site-packages (from altair->bermuda-ledger) (25.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.11/site-packages (from altair->bermuda-ledger) (4.15.0)\n",
      "Requirement already satisfied: boto3<2,>=1.20.32 in ./.venv/lib/python3.11/site-packages (from awswrangler->bermuda-ledger) (1.40.18)\n",
      "Requirement already satisfied: botocore<2,>=1.23.32 in ./.venv/lib/python3.11/site-packages (from awswrangler->bermuda-ledger) (1.40.18)\n",
      "Requirement already satisfied: pyarrow<21.0.0,>=18.0.0 in ./.venv/lib/python3.11/site-packages (from awswrangler->bermuda-ledger) (20.0.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in ./.venv/lib/python3.11/site-packages (from boto3<2,>=1.20.32->awswrangler->bermuda-ledger) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in ./.venv/lib/python3.11/site-packages (from boto3<2,>=1.20.32->awswrangler->bermuda-ledger) (0.13.1)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in ./.venv/lib/python3.11/site-packages (from botocore<2,>=1.23.32->awswrangler->bermuda-ledger) (2.5.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./.venv/lib/python3.11/site-packages (from jsonschema>=3.0->altair->bermuda-ledger) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.11/site-packages (from jsonschema>=3.0->altair->bermuda-ledger) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.11/site-packages (from jsonschema>=3.0->altair->bermuda-ledger) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.11/site-packages (from jsonschema>=3.0->altair->bermuda-ledger) (0.27.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>1.4.1->bermuda-ledger) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->altair->bermuda-ledger) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install bermuda-ledger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'plot_data_completeness' from 'bermuda.plot' (/Users/austinbrian/ldgr/bermuda-clrs-workshop-2025/.venv/lib/python3.11/site-packages/bermuda/plot.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbermuda\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtri\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ldgr/bermuda-clrs-workshop-2025/.venv/lib/python3.11/site-packages/bermuda/__init__.py:18\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatrix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     DisaggregatedValue,\n\u001b[32m     10\u001b[39m     Matrix,\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     RichMatrix,\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfactory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Triangle\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtriangle\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TriangleSlice\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdate_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ldgr/bermuda-clrs-workshop-2025/.venv/lib/python3.11/site-packages/bermuda/factory.py:41\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtriangle\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Triangle\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     27\u001b[39m     add_statics,\n\u001b[32m     28\u001b[39m     aggregate,\n\u001b[32m   (...)\u001b[39m\u001b[32m     39\u001b[39m     to_incremental,\n\u001b[32m     40\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     42\u001b[39m     plot_data_completeness,\n\u001b[32m     43\u001b[39m     plot_right_edge,\n\u001b[32m     44\u001b[39m     plot_heatmap,\n\u001b[32m     45\u001b[39m     plot_atas,\n\u001b[32m     46\u001b[39m     plot_growth_curve,\n\u001b[32m     47\u001b[39m     plot_mountain,\n\u001b[32m     48\u001b[39m     plot_sunset,\n\u001b[32m     49\u001b[39m     plot_ballistic,\n\u001b[32m     50\u001b[39m     plot_broom,\n\u001b[32m     51\u001b[39m     plot_drip,\n\u001b[32m     52\u001b[39m     plot_hose,\n\u001b[32m     53\u001b[39m     plot_histogram,\n\u001b[32m     54\u001b[39m )\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# utils\u001b[39;00m\n\u001b[32m     57\u001b[39m Triangle.aggregate = wraps(aggregate)(\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28mself\u001b[39m, *args, **kwargs: aggregate(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m     59\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'plot_data_completeness' from 'bermuda.plot' (/Users/austinbrian/ldgr/bermuda-clrs-workshop-2025/.venv/lib/python3.11/site-packages/bermuda/plot.py)"
     ]
    }
   ],
   "source": [
    "import bermuda as tri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Wide CSV Format Ingestion\n",
    "\n",
    "Wide CSV format represents the traditional actuarial triangle layout where:\n",
    "- Rows represent accident/occurrence periods\n",
    "- Columns represent development periods\n",
    "- Each cell contains loss values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample wide CSV data\n",
    "wide_csv_data = \"\"\"\n",
    "accident_year,dev_0,dev_12,dev_24,dev_36,dev_48\n",
    "2019,1000000,1200000,1250000,1275000,1280000\n",
    "2020,1100000,1350000,1400000,1420000,\n",
    "2021,950000,1180000,1220000,,\n",
    "2022,1200000,1450000,,,\n",
    "2023,1050000,,,,\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"Wide CSV Format Example:\")\n",
    "print(wide_csv_data)\n",
    "\n",
    "# Convert to DataFrame for processing\n",
    "wide_df = pd.read_csv(io.StringIO(wide_csv_data))\n",
    "print(\"\\nDataFrame representation:\")\n",
    "display(wide_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert wide format to triangle using bermuda's wide_csv_to_triangle function\n",
    "# Note: This assumes bermuda has this function - we'll simulate the conversion process\n",
    "\n",
    "def wide_csv_to_triangle_demo(df):\n",
    "    \"\"\"Demonstrate converting wide CSV format to bermuda triangle\"\"\"\n",
    "    cells = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        accident_year = row['accident_year']\n",
    "        \n",
    "        # Convert each development period to a cell\n",
    "        for col in df.columns[1:]:  # Skip accident_year column\n",
    "            if pd.notna(row[col]):\n",
    "                dev_months = int(col.split('_')[1])  # Extract development months\n",
    "                \n",
    "                period_start = date(accident_year, 1, 1)\n",
    "                period_end = date(accident_year, 12, 31)\n",
    "                \n",
    "                # Calculate evaluation date\n",
    "                if dev_months == 0:\n",
    "                    eval_date = period_end\n",
    "                else:\n",
    "                    eval_year = accident_year + (dev_months // 12)\n",
    "                    eval_month = 12 + (dev_months % 12)\n",
    "                    if eval_month > 12:\n",
    "                        eval_year += 1\n",
    "                        eval_month -= 12\n",
    "                    eval_date = date(eval_year, eval_month, 31)\n",
    "                \n",
    "                cell_data = {\n",
    "                    'period_start': period_start,\n",
    "                    'period_end': period_end,\n",
    "                    'evaluation_date': eval_date,\n",
    "                    'reported_loss': float(row[col])\n",
    "                }\n",
    "                cells.append(cell_data)\n",
    "    \n",
    "    return pd.DataFrame(cells)\n",
    "\n",
    "# Convert and display\n",
    "triangle_data = wide_csv_to_triangle_demo(wide_df)\n",
    "print(\"Converted to triangle format:\")\n",
    "display(triangle_data.head(10))\n",
    "print(f\"Total cells: {len(triangle_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Long CSV Format Ingestion\n",
    "\n",
    "Long CSV format is database-normalized format where:\n",
    "- Each row represents a single cell observation\n",
    "- Columns include period identifiers, evaluation dates, and loss values\n",
    "- Multiple fields can be included in the same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample long CSV data\n",
    "long_csv_data = \"\"\"\n",
    "accident_year,evaluation_date,reported_loss,paid_loss,earned_premium,line_of_business\n",
    "2019,2019-12-31,1000000,800000,5000000,Auto\n",
    "2019,2020-12-31,1200000,950000,5000000,Auto\n",
    "2019,2021-12-31,1250000,1100000,5000000,Auto\n",
    "2019,2022-12-31,1275000,1180000,5000000,Auto\n",
    "2020,2020-12-31,1100000,850000,5200000,Auto\n",
    "2020,2021-12-31,1350000,1050000,5200000,Auto\n",
    "2020,2022-12-31,1400000,1200000,5200000,Auto\n",
    "2021,2021-12-31,950000,750000,4800000,Auto\n",
    "2021,2022-12-31,1180000,900000,4800000,Auto\n",
    "2022,2022-12-31,1200000,900000,5100000,Auto\n",
    "2019,2019-12-31,800000,600000,3000000,Property\n",
    "2019,2020-12-31,950000,750000,3000000,Property\n",
    "2019,2021-12-31,980000,850000,3000000,Property\n",
    "2020,2020-12-31,850000,650000,3100000,Property\n",
    "2020,2021-12-31,1050000,800000,3100000,Property\n",
    "2021,2021-12-31,750000,580000,2900000,Property\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"Long CSV Format Example:\")\n",
    "long_df = pd.read_csv(io.StringIO(long_csv_data))\n",
    "long_df['evaluation_date'] = pd.to_datetime(long_df['evaluation_date']).dt.date\n",
    "display(long_df.head(10))\n",
    "print(f\"Total records: {len(long_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate long format advantages\n",
    "print(\"Long format advantages:\")\n",
    "print(f\"1. Multiple fields: {[col for col in long_df.columns if 'loss' in col or 'premium' in col]}\")\n",
    "print(f\"2. Multiple segments: {long_df['line_of_business'].unique()}\")\n",
    "print(f\"3. Metadata preservation: Each record includes line_of_business\")\n",
    "\n",
    "# Show data by segment\n",
    "print(\"\\nData by line of business:\")\n",
    "for lob in long_df['line_of_business'].unique():\n",
    "    lob_data = long_df[long_df['line_of_business'] == lob]\n",
    "    print(f\"{lob}: {len(lob_data)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert long format to triangle-ready format\n",
    "def long_csv_to_triangle_demo(df):\n",
    "    \"\"\"Convert long CSV to triangle format with metadata\"\"\"\n",
    "    triangle_cells = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        accident_year = row['accident_year']\n",
    "        eval_date = row['evaluation_date']\n",
    "        \n",
    "        cell_data = {\n",
    "            'period_start': date(accident_year, 1, 1),\n",
    "            'period_end': date(accident_year, 12, 31),\n",
    "            'evaluation_date': eval_date,\n",
    "            'reported_loss': row['reported_loss'],\n",
    "            'paid_loss': row['paid_loss'],\n",
    "            'earned_premium': row['earned_premium'],\n",
    "            'line_of_business': row['line_of_business']\n",
    "        }\n",
    "        triangle_cells.append(cell_data)\n",
    "    \n",
    "    return pd.DataFrame(triangle_cells)\n",
    "\n",
    "# Convert long format\n",
    "long_triangle_data = long_csv_to_triangle_demo(long_df)\n",
    "print(\"Converted long format to triangle structure:\")\n",
    "display(long_triangle_data.head())\n",
    "\n",
    "# Show multi-slice capability\n",
    "print(\"\\nMulti-slice triangle structure:\")\n",
    "for lob in long_triangle_data['line_of_business'].unique():\n",
    "    lob_data = long_triangle_data[long_triangle_data['line_of_business'] == lob]\n",
    "    print(f\"{lob} slice: {len(lob_data)} cells\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Actuarial Triangle-Shaped Format\n",
    "\n",
    "This format represents the classic actuarial triangle visualization where data is arranged in a triangular matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a triangle-shaped array (classic actuarial format)\n",
    "triangle_array = np.array([\n",
    "    [1000000, 1200000, 1250000, 1275000, 1280000],\n",
    "    [1100000, 1350000, 1400000, 1420000, np.nan],\n",
    "    [950000,  1180000, 1220000, np.nan,   np.nan],\n",
    "    [1200000, 1450000, np.nan,   np.nan,   np.nan],\n",
    "    [1050000, np.nan,   np.nan,   np.nan,   np.nan]\n",
    "])\n",
    "\n",
    "accident_years = [2019, 2020, 2021, 2022, 2023]\n",
    "development_periods = [0, 12, 24, 36, 48]  # months\n",
    "\n",
    "print(\"Triangle-shaped array:\")\n",
    "print(\"Accident Years (rows) vs Development Periods (columns)\")\n",
    "print(\"Development Periods:\", development_periods)\n",
    "print()\n",
    "\n",
    "for i, year in enumerate(accident_years):\n",
    "    row_str = f\"{year}: \"\n",
    "    for j, val in enumerate(triangle_array[i]):\n",
    "        if not np.isnan(val):\n",
    "            row_str += f\"{val:>10.0f} \"\n",
    "        else:\n",
    "            row_str += f\"{'':>10} \"\n",
    "    print(row_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert triangle array to bermuda format using array_triangle_builder concept\n",
    "def array_triangle_builder_demo(triangle_array, accident_years, development_periods):\n",
    "    \"\"\"Build triangle from array using bermuda array_triangle_builder concept\"\"\"\n",
    "    cells = []\n",
    "    \n",
    "    for i, accident_year in enumerate(accident_years):\n",
    "        for j, dev_period in enumerate(development_periods):\n",
    "            value = triangle_array[i, j]\n",
    "            \n",
    "            if not np.isnan(value):\n",
    "                period_start = date(accident_year, 1, 1)\n",
    "                period_end = date(accident_year, 12, 31)\n",
    "                \n",
    "                # Calculate evaluation date based on development period\n",
    "                if dev_period == 0:\n",
    "                    eval_date = period_end\n",
    "                else:\n",
    "                    eval_year = accident_year + (dev_period // 12)\n",
    "                    eval_month = 12 + (dev_period % 12)\n",
    "                    if eval_month > 12:\n",
    "                        eval_year += 1\n",
    "                        eval_month -= 12\n",
    "                    eval_date = date(eval_year, eval_month, 31)\n",
    "                \n",
    "                cell = {\n",
    "                    'period_start': period_start,\n",
    "                    'period_end': period_end,\n",
    "                    'evaluation_date': eval_date,\n",
    "                    'development_period': dev_period,\n",
    "                    'reported_loss': value,\n",
    "                    'array_position': f'[{i},{j}]'\n",
    "                }\n",
    "                cells.append(cell)\n",
    "    \n",
    "    return pd.DataFrame(cells)\n",
    "\n",
    "# Build triangle from array\n",
    "array_triangle_data = array_triangle_builder_demo(triangle_array, accident_years, development_periods)\n",
    "print(\"Array-based triangle conversion:\")\n",
    "display(array_triangle_data)\n",
    "\n",
    "print(f\"\\nSuccessfully converted {len(array_triangle_data)} cells from triangle array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Excel Spreadsheet Ingestion\n",
    "\n",
    "Many actuaries work with Excel files. Let's demonstrate creating and reading triangle data from Excel format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample Excel-like data structure\n",
    "excel_triangle_data = {\n",
    "    'Accident Year': [2019, 2020, 2021, 2022, 2023],\n",
    "    '0 months': [1000000, 1100000, 950000, 1200000, 1050000],\n",
    "    '12 months': [1200000, 1350000, 1180000, 1450000, None],\n",
    "    '24 months': [1250000, 1400000, 1220000, None, None],\n",
    "    '36 months': [1275000, 1420000, None, None, None],\n",
    "    '48 months': [1280000, None, None, None, None]\n",
    "}\n",
    "\n",
    "excel_df = pd.DataFrame(excel_triangle_data)\n",
    "print(\"Excel-style triangle data:\")\n",
    "display(excel_df)\n",
    "\n",
    "# Save as Excel file for demonstration\n",
    "excel_filename = 'sample_triangle.xlsx'\n",
    "try:\n",
    "    excel_df.to_excel(excel_filename, index=False)\n",
    "    print(f\"\\nSaved sample data to {excel_filename}\")\n",
    "except ImportError:\n",
    "    print(\"\\nNote: openpyxl not available for Excel export, but format demonstrated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Excel-style data to triangle format\n",
    "def excel_to_triangle_demo(df):\n",
    "    \"\"\"Convert Excel-style triangle to bermuda format\"\"\"\n",
    "    cells = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        accident_year = row['Accident Year']\n",
    "        \n",
    "        # Process development columns\n",
    "        for col in df.columns[1:]:  # Skip 'Accident Year'\n",
    "            if pd.notna(row[col]):\n",
    "                # Extract development period from column name\n",
    "                dev_months = int(col.split()[0])  # e.g., \"12 months\" -> 12\n",
    "                \n",
    "                period_start = date(accident_year, 1, 1)\n",
    "                period_end = date(accident_year, 12, 31)\n",
    "                \n",
    "                # Calculate evaluation date\n",
    "                if dev_months == 0:\n",
    "                    eval_date = period_end\n",
    "                else:\n",
    "                    eval_year = accident_year + (dev_months // 12)\n",
    "                    eval_month = 12 + (dev_months % 12)\n",
    "                    if eval_month > 12:\n",
    "                        eval_year += 1\n",
    "                        eval_month -= 12\n",
    "                    eval_date = date(eval_year, eval_month, 31)\n",
    "                \n",
    "                cell = {\n",
    "                    'period_start': period_start,\n",
    "                    'period_end': period_end,\n",
    "                    'evaluation_date': eval_date,\n",
    "                    'development_months': dev_months,\n",
    "                    'reported_loss': float(row[col]),\n",
    "                    'source_format': 'Excel'\n",
    "                }\n",
    "                cells.append(cell)\n",
    "    \n",
    "    return pd.DataFrame(cells)\n",
    "\n",
    "# Convert Excel data\n",
    "excel_triangle_converted = excel_to_triangle_demo(excel_df)\n",
    "print(\"Excel data converted to triangle format:\")\n",
    "display(excel_triangle_converted.head(10))\n",
    "print(f\"\\nTotal cells from Excel format: {len(excel_triangle_converted)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Chain-Ladder Package I/O\n",
    "\n",
    "Demonstrate interoperability with the popular chainladder package for R/Python actuarial work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate chainladder package format (since it may not be installed)\n",
    "# This demonstrates the concept of converting between different actuarial libraries\n",
    "\n",
    "def simulate_chainladder_triangle():\n",
    "    \"\"\"Simulate a triangle in chainladder package format\"\"\"\n",
    "    # Chainladder typically uses arrays with specific indexing\n",
    "    cl_data = {\n",
    "        'values': triangle_array,  # The loss triangle array\n",
    "        'origin': accident_years,   # Accident years\n",
    "        'development': development_periods,  # Development periods\n",
    "        'valuation': None  # Calculated from origin + development\n",
    "    }\n",
    "    \n",
    "    # Calculate valuation dates\n",
    "    valuation_dates = []\n",
    "    for i, origin_year in enumerate(cl_data['origin']):\n",
    "        val_row = []\n",
    "        for j, dev_period in enumerate(cl_data['development']):\n",
    "            if not np.isnan(cl_data['values'][i, j]):\n",
    "                val_year = origin_year + (dev_period // 12)\n",
    "                val_month = 12 + (dev_period % 12)\n",
    "                if val_month > 12:\n",
    "                    val_year += 1\n",
    "                    val_month -= 12\n",
    "                val_row.append(date(val_year, val_month, 31))\n",
    "            else:\n",
    "                val_row.append(None)\n",
    "        valuation_dates.append(val_row)\n",
    "    \n",
    "    cl_data['valuation'] = valuation_dates\n",
    "    return cl_data\n",
    "\n",
    "# Create simulated chainladder triangle\n",
    "cl_triangle = simulate_chainladder_triangle()\n",
    "print(\"Simulated Chain-Ladder package triangle:\")\n",
    "print(f\"Origin periods: {cl_triangle['origin']}\")\n",
    "print(f\"Development periods: {cl_triangle['development']}\")\n",
    "print(f\"Triangle shape: {cl_triangle['values'].shape}\")\n",
    "print(\"\\nSample valuation dates:\")\n",
    "for i in range(min(3, len(cl_triangle['valuation']))):\n",
    "    valid_dates = [d for d in cl_triangle['valuation'][i] if d is not None]\n",
    "    print(f\"  Origin {cl_triangle['origin'][i]}: {valid_dates[:3]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert chainladder format to bermuda\n",
    "def chainladder_to_bermuda_demo(cl_data):\n",
    "    \"\"\"Convert chainladder-style data to bermuda triangle format\"\"\"\n",
    "    cells = []\n",
    "    \n",
    "    for i, origin_year in enumerate(cl_data['origin']):\n",
    "        for j, dev_period in enumerate(cl_data['development']):\n",
    "            value = cl_data['values'][i, j]\n",
    "            valuation_date = cl_data['valuation'][i][j]\n",
    "            \n",
    "            if not np.isnan(value) and valuation_date is not None:\n",
    "                cell = {\n",
    "                    'period_start': date(origin_year, 1, 1),\n",
    "                    'period_end': date(origin_year, 12, 31),\n",
    "                    'evaluation_date': valuation_date,\n",
    "                    'development_period': dev_period,\n",
    "                    'reported_loss': value,\n",
    "                    'origin_year': origin_year,\n",
    "                    'source_package': 'chainladder'\n",
    "                }\n",
    "                cells.append(cell)\n",
    "    \n",
    "    return pd.DataFrame(cells)\n",
    "\n",
    "# Convert chainladder to bermuda\n",
    "cl_to_bermuda = chainladder_to_bermuda_demo(cl_triangle)\n",
    "print(\"Chain-ladder format converted to Bermuda:\")\n",
    "display(cl_to_bermuda.head())\n",
    "print(f\"\\nSuccessfully converted {len(cl_to_bermuda)} cells from chainladder format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Trib Files (Binary Triangle Format)\n",
    "\n",
    "Trib files are Bermuda's native binary format for efficient triangle storage and retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the existing trib file from our test data\n",
    "trib_file = \"data/solm.gl-general.trib\"\n",
    "\n",
    "if os.path.exists(trib_file):\n",
    "    print(f\"Loading triangle from trib file: {trib_file}\")\n",
    "    trib_triangle = tri.binary_to_triangle(trib_file)\n",
    "    print(\"\\nTrib file triangle summary:\")\n",
    "    print(trib_triangle)\n",
    "    \n",
    "    print(f\"\\nTrib file advantages:\")\n",
    "    print(f\"- Fast binary loading\")\n",
    "    print(f\"- Preserves all metadata\")\n",
    "    print(f\"- Compact storage\")\n",
    "    print(f\"- Native bermuda format\")\n",
    "    \n",
    "    # Show file size\n",
    "    file_size = os.path.getsize(trib_file)\n",
    "    print(f\"\\nFile size: {file_size:,} bytes ({file_size/1024/1024:.2f} MB)\")\n",
    "    print(f\"Cells per byte: {len(trib_triangle)/file_size:.2f}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Trib file not found: {trib_file}\")\n",
    "    print(\"Trib files provide efficient binary storage for bermuda triangles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate trib file creation concept\n",
    "def simulate_trib_creation(triangle_df, filename=\"sample.trib\"):\n",
    "    \"\"\"Simulate creating a trib file from triangle data\"\"\"\n",
    "    print(f\"Would create trib file: {filename}\")\n",
    "    print(f\"Input data: {len(triangle_df)} cells\")\n",
    "    \n",
    "    # Show what would be stored\n",
    "    required_fields = ['period_start', 'period_end', 'evaluation_date']\n",
    "    value_fields = [col for col in triangle_df.columns if 'loss' in col.lower() or 'premium' in col.lower()]\n",
    "    metadata_fields = [col for col in triangle_df.columns if col not in required_fields + value_fields]\n",
    "    \n",
    "    print(f\"Required fields: {required_fields}\")\n",
    "    print(f\"Value fields: {value_fields}\")\n",
    "    print(f\"Metadata fields: {metadata_fields}\")\n",
    "    \n",
    "    return {\n",
    "        'filename': filename,\n",
    "        'cell_count': len(triangle_df),\n",
    "        'fields': required_fields + value_fields,\n",
    "        'metadata': metadata_fields\n",
    "    }\n",
    "\n",
    "# Simulate creating trib from our converted data\n",
    "if len(long_triangle_data) > 0:\n",
    "    # Use our long format data\n",
    "    trib_info = simulate_trib_creation(long_triangle_data, \"multi_slice_example.trib\")\n",
    "    print(f\"\\nWould create trib file with:\")\n",
    "    print(f\"  {trib_info['cell_count']} cells\")\n",
    "    print(f\"  {len(trib_info['fields'])} value fields\")\n",
    "    print(f\"  {len(trib_info['metadata'])} metadata fields\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Validation and Quality Checks\n",
    "\n",
    "When ingesting data from various sources, it's important to validate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_triangle_data(df, source_name):\n",
    "    \"\"\"Validate converted triangle data\"\"\"\n",
    "    print(f\"\\nValidating {source_name} data:\")\n",
    "    \n",
    "    # Check required fields\n",
    "    required_fields = ['period_start', 'period_end', 'evaluation_date']\n",
    "    missing_fields = [f for f in required_fields if f not in df.columns]\n",
    "    if missing_fields:\n",
    "        print(f\"  X Missing required fields: {missing_fields}\")\n",
    "    else:\n",
    "        print(f\"  ✓ All required fields present\")\n",
    "    \n",
    "    # Check for valid dates\n",
    "    try:\n",
    "        date_columns = [col for col in df.columns if 'date' in col]\n",
    "        for col in date_columns:\n",
    "            if df[col].isnull().any():\n",
    "                print(f\"  ! Null dates found in {col}\")\n",
    "            else:\n",
    "                print(f\"  ✓ Valid dates in {col}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  X Date validation error: {e}\")\n",
    "    \n",
    "    # Check for value fields\n",
    "    value_fields = [col for col in df.columns if 'loss' in col.lower() or 'premium' in col.lower()]\n",
    "    if not value_fields:\n",
    "        print(f\"  ! No value fields found\")\n",
    "    else:\n",
    "        print(f\"  ✓ Value fields found: {value_fields}\")\n",
    "    \n",
    "    # Check for negative values\n",
    "    for col in value_fields:\n",
    "        if (df[col] < 0).any():\n",
    "            print(f\"  ! Negative values found in {col}\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"  Total cells: {len(df)}\")\n",
    "    if len(df) > 0:\n",
    "        print(f\"  Period range: {df['period_start'].min()} to {df['period_end'].max()}\")\n",
    "        print(f\"  Evaluation range: {df['evaluation_date'].min()} to {df['evaluation_date'].max()}\")\n",
    "    \n",
    "    return len(missing_fields) == 0\n",
    "\n",
    "# Validate all our converted datasets\n",
    "datasets = [\n",
    "    (triangle_data, \"Wide CSV\"),\n",
    "    (long_triangle_data, \"Long CSV\"),\n",
    "    (array_triangle_data, \"Array Format\"),\n",
    "    (excel_triangle_converted, \"Excel Format\"),\n",
    "    (cl_to_bermuda, \"Chain-ladder Format\")\n",
    "]\n",
    "\n",
    "valid_datasets = []\n",
    "for dataset, name in datasets:\n",
    "    if len(dataset) > 0:\n",
    "        is_valid = validate_triangle_data(dataset, name)\n",
    "        if is_valid:\n",
    "            valid_datasets.append((dataset, name))\n",
    "\n",
    "print(f\"\\nSuccessfully validated {len(valid_datasets)} datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualization of Ingested Data\n",
    "\n",
    "Let's create visualizations to compare the different ingestion methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare data coverage across ingestion methods\n",
    "coverage_comparison = []\n",
    "\n",
    "for dataset, name in valid_datasets:\n",
    "    if len(dataset) > 0:\n",
    "        period_count = len(dataset['period_start'].unique())\n",
    "        eval_count = len(dataset['evaluation_date'].unique())\n",
    "        avg_loss = dataset['reported_loss'].mean() if 'reported_loss' in dataset.columns else 0\n",
    "        \n",
    "        coverage_comparison.append({\n",
    "            'Format': name,\n",
    "            'Cell Count': len(dataset),\n",
    "            'Accident Periods': period_count,\n",
    "            'Evaluation Dates': eval_count,\n",
    "            'Avg Reported Loss': avg_loss\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(coverage_comparison)\n",
    "print(\"Ingestion Method Comparison:\")\n",
    "display(comparison_df)\n",
    "\n",
    "# Create a simple visualization\n",
    "if len(comparison_df) > 0:\n",
    "    # Cell count comparison\n",
    "    chart = alt.Chart(comparison_df).mark_bar().encode(\n",
    "        x=alt.X('Format:N', title='Ingestion Format'),\n",
    "        y=alt.Y('Cell Count:Q', title='Number of Cells'),\n",
    "        color=alt.Color('Format:N', legend=None),\n",
    "        tooltip=['Format', 'Cell Count', 'Accident Periods', 'Evaluation Dates']\n",
    "    ).properties(\n",
    "        title='Triangle Cells by Ingestion Format',\n",
    "        width=400,\n",
    "        height=300\n",
    "    )\n",
    "    \n",
    "    chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Best Practices and Recommendations\n",
    "\n",
    "Summary of ingestion best practices based on different use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display best practices guide\n",
    "best_practices = {\n",
    "    \"Wide CSV\": {\n",
    "        \"Best for\": \"Traditional actuarial triangles, simple data\",\n",
    "        \"Advantages\": [\"Familiar format\", \"Easy to create in Excel\", \"Visual triangle structure\"],\n",
    "        \"Disadvantages\": [\"Limited metadata\", \"Single field only\", \"Sparse for irregular triangles\"]\n",
    "    },\n",
    "    \"Long CSV\": {\n",
    "        \"Best for\": \"Database exports, multi-field data, segmented triangles\",\n",
    "        \"Advantages\": [\"Multiple fields\", \"Rich metadata\", \"Database-friendly\", \"Multi-slice support\"],\n",
    "        \"Disadvantages\": [\"Less intuitive format\", \"Larger file sizes\"]\n",
    "    },\n",
    "    \"Array Format\": {\n",
    "        \"Best for\": \"Mathematical operations, chainladder compatibility\",\n",
    "        \"Advantages\": [\"Efficient for calculations\", \"Standard actuarial format\", \"Easy matrix operations\"],\n",
    "        \"Disadvantages\": [\"Fixed structure\", \"Limited metadata\", \"Requires index management\"]\n",
    "    },\n",
    "    \"Excel Format\": {\n",
    "        \"Best for\": \"Actuarial workflows, presentation data\",\n",
    "        \"Advantages\": [\"Familiar to actuaries\", \"Easy editing\", \"Good for small datasets\"],\n",
    "        \"Disadvantages\": [\"Version compatibility\", \"Size limitations\", \"Manual process\"]\n",
    "    },\n",
    "    \"Trib Files\": {\n",
    "        \"Best for\": \"Production systems, large datasets, archival storage\",\n",
    "        \"Advantages\": [\"Fast loading\", \"Compact storage\", \"Full metadata\", \"Native format\"],\n",
    "        \"Disadvantages\": [\"Binary format\", \"Requires bermuda to read\", \"Less portable\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"BERMUDA INGESTION BEST PRACTICES\\n\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for format_name, info in best_practices.items():\n",
    "    print(f\"\\n{format_name}\")\n",
    "    print(f\"   Best for: {info['Best for']}\")\n",
    "    print(f\"   ✓ Advantages: {', '.join(info['Advantages'])}\")\n",
    "    print(f\"   ! Disadvantages: {', '.join(info['Disadvantages'])}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"GENERAL RECOMMENDATIONS:\")\n",
    "print(\"   • Use Long CSV for complex, multi-dimensional data\")\n",
    "print(\"   • Use Wide CSV for simple, single-field triangles\")\n",
    "print(\"   • Use Trib files for production and archival storage\")\n",
    "print(\"   • Validate all data after ingestion\")\n",
    "print(\"   • Preserve metadata whenever possible\")\n",
    "print(\"   • Consider data volume and performance requirements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has demonstrated comprehensive data ingestion capabilities for the Bermuda library:\n",
    "\n",
    "1. **Wide CSV Format** - Traditional triangle layout for simple data\n",
    "2. **Long CSV Format** - Database-normalized format for complex, multi-dimensional data\n",
    "3. **Array Format** - Mathematical matrix format for computational work\n",
    "4. **Excel Integration** - Working with spreadsheet data common in actuarial workflows\n",
    "5. **Chain-ladder Compatibility** - Interoperability with other actuarial libraries\n",
    "6. **Trib Files** - Native binary format for efficient storage and retrieval\n",
    "7. **Data Validation** - Quality checks and validation procedures\n",
    "8. **Best Practices** - Guidance for choosing the right ingestion method\n",
    "\n",
    "Each method has its strengths and appropriate use cases. The key is selecting the right approach based on your data structure, workflow requirements, and performance needs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
