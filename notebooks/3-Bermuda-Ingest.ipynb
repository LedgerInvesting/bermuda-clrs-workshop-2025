{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triangle Ingest\n",
    "\n",
    "This notebook demonstrates how to ingest triangle data from various external formats into Bermuda. We'll work with Excel and CSV files in different formats: long, wide, and array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bermuda as tri\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from datetime import date\n",
    "import os\n",
    "\n",
    "# Enable HTML rendering\n",
    "alt.renderers.enable(\"html\")\n",
    "\n",
    "# Check that our data files exist\n",
    "if not os.path.exists('data/excel/triangle_data.xlsx'):\n",
    "    print(\"Data files not found. Running data generation script...\")\n",
    "    !python create_excel_data.py\n",
    "else:\n",
    "    print(\"Data files found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Data Formats\n",
    "\n",
    "Bermuda supports three main tabular formats for triangle data:\n",
    "\n",
    "1. **Long Format**: Each row represents a single cell value\n",
    "2. **Wide Format**: Each row represents all values for a cell\n",
    "3. **Array Format**: Traditional actuarial triangle layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Long Format Ingestion\n",
    "\n",
    "Long format is the most flexible - each row contains one value for one cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and examine the long format CSV\n",
    "gl_long_df = pd.read_csv('data/excel/gl_long.csv')\n",
    "print(\"Long format structure (first 5 rows):\")\n",
    "display(gl_long_df.head())\n",
    "print(f\"\\nShape: {gl_long_df.shape}\")\n",
    "print(f\"Columns: {list(gl_long_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest long format CSV\n",
    "gl_triangle = tri.long_csv_to_triangle('data/excel/gl_long.csv')\n",
    "print(\"Triangle loaded from long CSV:\")\n",
    "display(gl_triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the renamed columns - we need to fix the mapping\n",
    "# The CSV has 'paid_losses' but Bermuda expects 'paid_loss'\n",
    "# Let's reload with proper column mapping\n",
    "\n",
    "# First, load as DataFrame and rename columns\n",
    "gl_df = pd.read_csv('data/excel/gl_long.csv')\n",
    "gl_df = gl_df.rename(columns={\n",
    "    'paid_losses': 'paid_loss',\n",
    "    'incurred_losses': 'reported_loss',\n",
    "    'earned_prem': 'earned_premium'\n",
    "})\n",
    "\n",
    "gl_df['period_start'] = pd.to_datetime(gl_df['period_start'])\n",
    "gl_df['period_end'] = pd.to_datetime(gl_df['period_end'])\n",
    "gl_df['evaluation_date'] = pd.to_datetime(gl_df['evaluation_date'])\n",
    "\n",
    "# Now ingest from DataFrame\n",
    "gl_triangle = tri.long_data_frame_to_triangle(gl_df)\n",
    "print(\"Triangle with corrected column names:\")\n",
    "print(gl_triangle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Wide Format Ingestion\n",
    "\n",
    "Wide format has one row per cell with all fields as columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wide format from Excel\n",
    "ca_wide_df = pd.read_excel('data/excel/triangle_data.xlsx', sheet_name='ca_wide_format')\n",
    "print(\"Wide format structure (first 5 rows):\")\n",
    "display(ca_wide_df.head())\n",
    "print(f\"\\nShape: {ca_wide_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest wide format\n",
    "ca_triangle = tri.wide_data_frame_to_triangle(ca_wide_df, field_cols=['paid_loss','reported_loss','earned_premium'])\n",
    "print(\"Triangle loaded from wide format:\")\n",
    "display(ca_triangle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Array Format Ingestion\n",
    "\n",
    "Array format is the traditional actuarial triangle layout with accident periods as rows and development periods as columns.\n",
    "\n",
    "Here we show some messier data, as it actually exists in the real world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the messy array format from Excel - all three triangles in one sheet!\n",
    "# This mimics real-world data where multiple triangles are stacked\n",
    "import pandas as pd\n",
    "\n",
    "# Read the entire sheet\n",
    "pa_raw_df = pd.read_excel('data/excel/triangle_data.xlsx', sheet_name='pa_array_format', header=None)\n",
    "print(\"Raw messy sheet structure (first 15 rows):\")\n",
    "display(pa_raw_df.head(18))\n",
    "print(f\"\\nTotal sheet shape: {pa_raw_df.shape}\")\n",
    "\n",
    "# We need to parse this messy format and extract the three triangles\n",
    "print(\"\\nLet's see what we're dealing with - finding the section headers...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the messy Excel sheet to extract the three triangles\n",
    "def parse_messy_triangles(df):\n",
    "    \"\"\"Parse a messy Excel sheet with multiple triangles separated by blank rows\"\"\"\n",
    "    # Find the section headers\n",
    "    sections = {}\n",
    "    current_section = None\n",
    "    section_start = None\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        # Check if this row contains a section header\n",
    "        if pd.notna(row.iloc[0]) and isinstance(row.iloc[0], str):\n",
    "            header_text = str(row.iloc[0]).upper().strip()\n",
    "            if any(keyword in header_text for keyword in ['PAID LOSS', 'REPORTED LOSS', 'EARNED PREMIUM']):\n",
    "                # End previous section if it exists\n",
    "                if current_section is not None and section_start is not None:\n",
    "                    sections[current_section] = (section_start, idx - 1)\n",
    "                \n",
    "                # Start new section\n",
    "                if 'PAID' in header_text:\n",
    "                    current_section = 'paid_loss'\n",
    "                elif 'REPORTED' in header_text:\n",
    "                    current_section = 'reported_loss'\n",
    "                elif 'EARNED' in header_text or 'PREMIUM' in header_text:\n",
    "                    current_section = 'earned_premium'\n",
    "                section_start = idx + 1\n",
    "    \n",
    "    # Don't forget the last section\n",
    "    if current_section is not None and section_start is not None:\n",
    "        sections[current_section] = (section_start, len(df) - 1)\n",
    "    \n",
    "    print(f\"Found sections: {list(sections.keys())}\")\n",
    "    \n",
    "    # Extract each triangle\n",
    "    triangles = {}\n",
    "    for field, (start_row, end_row) in sections.items():\n",
    "        print(f\"\\nExtracting {field} from rows {start_row} to {end_row}\")\n",
    "        \n",
    "        # Get the data for this section\n",
    "        section_df = df.iloc[start_row:end_row + 1].copy()\n",
    "        \n",
    "        # Remove completely empty rows\n",
    "        section_df = section_df.dropna(how='all')\n",
    "        \n",
    "        # The first row should be the header\n",
    "        if len(section_df) > 0:\n",
    "            # Use first row as header\n",
    "            section_df.columns = section_df.iloc[0]\n",
    "            section_df = section_df.drop(section_df.index[0])\n",
    "            \n",
    "            # Reset index and clean up\n",
    "            section_df = section_df.reset_index(drop=True)\n",
    "            section_df.columns.name = None\n",
    "            \n",
    "            # Rename first column to 'period' if it looks like accident_period  \n",
    "            if section_df.columns[0] == 'accident_period' or pd.isna(section_df.columns[0]):\n",
    "                new_cols = ['period'] + [col for col in section_df.columns[1:]]\n",
    "                section_df.columns = new_cols\n",
    "            \n",
    "            triangles[field] = section_df\n",
    "            print(f\"  Shape: {section_df.shape}\")\n",
    "            print(f\"  Columns: {list(section_df.columns)}\")\n",
    "    \n",
    "    return triangles\n",
    "\n",
    "# Parse the messy sheet\n",
    "triangle_dfs = parse_messy_triangles(pa_raw_df)\n",
    "\n",
    "# Show what we extracted\n",
    "for field, df in triangle_dfs.items():\n",
    "    print(f\"\\n{field.upper()} triangle:\")\n",
    "    display(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now convert each parsed triangle to Bermuda format and merge them\n",
    "triangles = []\n",
    "\n",
    "for field, df in triangle_dfs.items():\n",
    "    print(f\"\\nConverting {field} triangle...\")\n",
    "    \n",
    "    # Clean up the DataFrame structure before conversion\n",
    "    clean_df = df.copy()\n",
    "    \n",
    "    # The DataFrame has duplicate 'period' columns - we need the second one with dates\n",
    "    # Remove the header row that says 'accident_period'\n",
    "    clean_df = clean_df[clean_df.iloc[:, 0] != 'accident_period']\n",
    "    \n",
    "    # Remove any rows that are completely empty\n",
    "    clean_df = clean_df.dropna(how='all')\n",
    "    \n",
    "    # Reset index\n",
    "    clean_df = clean_df.reset_index(drop=True)\n",
    "    \n",
    "    # The second column (index 1) contains the actual dates, use that as 'period'\n",
    "    if len(clean_df.columns) > 1:\n",
    "        # Create new DataFrame with proper structure\n",
    "        date_col = clean_df.iloc[:, 1]  # Second column has the dates\n",
    "        data_cols = clean_df.iloc[:, 2:]  # Rest are data columns\n",
    "        \n",
    "        # Build new DataFrame\n",
    "        new_df = pd.DataFrame()\n",
    "        new_df['period'] = date_col\n",
    "        \n",
    "        # Add data columns with proper names\n",
    "        for i, col in enumerate(data_cols.columns):\n",
    "            new_df[f\"dev_{col}\"] = data_cols.iloc[:, i]\n",
    "        \n",
    "        # Remove any rows where period is NaN\n",
    "        new_df = new_df.dropna(subset=['period'])\n",
    "        \n",
    "        print(f\"  Cleaned DataFrame shape: {new_df.shape}\")\n",
    "        print(f\"  First few periods: {new_df['period'].head(3).tolist()}\")\n",
    "        \n",
    "        # Convert to Bermuda triangle\n",
    "        triangle = tri.array_data_frame_to_triangle(\n",
    "            new_df,\n",
    "            field=field,\n",
    "            period_resolution=12,  # Annual periods\n",
    "            eval_resolution=12     # Annual evaluations\n",
    "        )\n",
    "        triangles.append(triangle)\n",
    "        print(f\"  Created triangle with {len(triangle)} cells\")\n",
    "\n",
    "# Merge all triangles into one with multiple fields\n",
    "if triangles:\n",
    "    pa_triangle = triangles[0]\n",
    "    for t in triangles[1:]:\n",
    "        pa_triangle = tri.merge(pa_triangle, t)\n",
    "    \n",
    "    print(f\"\\n🎉 Successfully created PA triangle from messy Excel data!\")\n",
    "    print(f\"Triangle has {len(pa_triangle)} cells\")\n",
    "    print(f\"Available fields: {pa_triangle.fields}\")\n",
    "    display(pa_triangle)\n",
    "else:\n",
    "    print(\"❌ Failed to extract triangles from the messy data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the power of having multiple fields in one triangle\n",
    "# Calculate loss ratios and case reserves automatically\n",
    "print(\"Sample cells showing all fields:\")\n",
    "for i, cell in enumerate(pa_triangle[:3]):\n",
    "    print(f\"\\nCell {i+1}:\")\n",
    "    print(f\"  Period: {cell.period_start} to {cell.period_end}\")\n",
    "    print(f\"  Evaluation: {cell.evaluation_date}\")\n",
    "    print(f\"  Paid Loss: ${cell.values.get('paid_loss', 0):,.0f}\")\n",
    "    print(f\"  Reported Loss: ${cell.values.get('reported_loss', 0):,.0f}\")\n",
    "    print(f\"  Earned Premium: ${cell.values.get('earned_premium', 0):,.0f}\")\n",
    "    \n",
    "    # Calculate derived metrics\n",
    "    if cell.values.get('earned_premium', 0) > 0:\n",
    "        paid_lr = cell.values.get('paid_loss', 0) / cell.values.get('earned_premium', 1)\n",
    "        reported_lr = cell.values.get('reported_loss', 0) / cell.values.get('earned_premium', 1)\n",
    "        print(f\"  Paid Loss Ratio: {paid_lr:.1%}\")\n",
    "        print(f\"  Reported Loss Ratio: {reported_lr:.1%}\")\n",
    "    \n",
    "    if cell.values.get('reported_loss', 0) > cell.values.get('paid_loss', 0):\n",
    "        case_reserves = cell.values.get('reported_loss', 0) - cell.values.get('paid_loss', 0)\n",
    "        print(f\"  Case Reserves: ${case_reserves:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Exercise: Load Your Own Data\n",
    "\n",
    "Now it's your turn! Complete the code below to load triangle data in different formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Load Wide Format CSV\n",
    "\n",
    "Complete the code to load the CA wide format from CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load ca_wide.csv using the appropriate Bermuda function\n",
    "# Hint: Use tri.wide_csv_to_triangle()\n",
    "\n",
    "# ca_triangle_csv = tri.________('data/excel/ca_wide.csv')\n",
    "# display(ca_triangle_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Load Array Format from CSV\n",
    "\n",
    "Complete the code to load PA array data from CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load pa_array.csv and convert to triangle\n",
    "# Remember: array format needs the field name!\n",
    "\n",
    "# pa_csv_df = pd.read_csv('data/excel/pa_array.csv')\n",
    "# pa_triangle_csv = tri.array_data_frame_to_triangle(\n",
    "#     pa_csv_df,\n",
    "#     field='______',  # What field should go here?\n",
    "#     period_resolution=___,  # Annual = ?\n",
    "#     eval_resolution=___     # Annual = ?\n",
    "# )\n",
    "# display(pa_triangle_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Handle Multiple Fields in Array Format\n",
    "\n",
    "Load both paid and reported losses from array format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a triangle with multiple fields from array format\n",
    "# Hint: Use tri.array_triangle_builder() with lists of DataFrames and field names\n",
    "\n",
    "# Load a sample triangle to get both fields\n",
    "# sample = tri.binary_to_triangle('data/excel/ca_filtered.trib')\n",
    "# \n",
    "# # Export to array format for both fields\n",
    "# paid_array = tri.triangle_to_array_data_frame(sample, field='paid_loss')\n",
    "# reported_array = tri.triangle_to_array_data_frame(sample, field='reported_loss')\n",
    "# \n",
    "# # Now build a multi-field triangle\n",
    "# multi_triangle = tri.array_triangle_builder(\n",
    "#     dfs=[_____, _____],  # List of DataFrames\n",
    "#     fields=['_____', '_____'],  # Corresponding field names\n",
    "#     period_resolution=12,\n",
    "#     eval_resolution=12\n",
    "# )\n",
    "# display(multi_triangle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Multi-Slice Triangles\n",
    "\n",
    "Now let's combine our three triangles (GL, CA, PA) into a single multi-slice triangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add metadata to distinguish the slices\n",
    "gl_cells = []\n",
    "for cell in gl_triangle:\n",
    "   # Create new metadata with same standard fields\n",
    "   new_meta = tri.Metadata(\n",
    "       risk_basis=cell.metadata.risk_basis,\n",
    "       reinsurance_basis=cell.metadata.reinsurance_basis,\n",
    "       loss_definition=cell.metadata.loss_definition,\n",
    "   )\n",
    "   # Copy existing details and add new field\n",
    "   new_meta.details.update(cell.metadata.details)\n",
    "   new_meta.details['line'] = 'GL'\n",
    "   gl_cells.append(cell.replace(metadata=new_meta))\n",
    "gl_with_meta = tri.Triangle(gl_cells)\n",
    "\n",
    "ca_cells = []\n",
    "for cell in ca_triangle:\n",
    "   # Create new metadata with same standard fields\n",
    "   new_meta = tri.Metadata(\n",
    "       risk_basis=cell.metadata.risk_basis,\n",
    "       reinsurance_basis=cell.metadata.reinsurance_basis,\n",
    "       loss_definition=cell.metadata.loss_definition,\n",
    "   )\n",
    "   # Copy existing details and add new field\n",
    "   new_meta.details.update(cell.metadata.details)\n",
    "   new_meta.details['line'] = 'CA'\n",
    "   ca_cells.append(cell.replace(metadata=new_meta))\n",
    "ca_with_meta = tri.Triangle(ca_cells)\n",
    "\n",
    "pa_cells = []\n",
    "for cell in pa_triangle:\n",
    "   # Create new metadata with same standard fields\n",
    "   new_meta = tri.Metadata(\n",
    "       risk_basis=cell.metadata.risk_basis,\n",
    "       reinsurance_basis=cell.metadata.reinsurance_basis,\n",
    "       loss_definition=cell.metadata.loss_definition,\n",
    "   )\n",
    "   # Copy existing details and add new field\n",
    "   new_meta.details.update(cell.metadata.details)\n",
    "   new_meta.details['line'] = 'PA'\n",
    "   pa_cells.append(cell.replace(metadata=new_meta))\n",
    "pa_with_meta = tri.Triangle(pa_cells)\n",
    "\n",
    "# Combine into multi-slice triangle\n",
    "combined = gl_with_meta + ca_with_meta + pa_with_meta\n",
    "print(\"Combined multi-slice triangle:\")\n",
    "display(combined)\n",
    "print(f\"\\nNumber of slices: {len(combined.slices)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.plot_right_edge()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Triangle Data\n",
    "\n",
    "Bermuda supports multiple output formats for saving your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV (long format)\n",
    "tri.triangle_to_long_csv(combined, 'data/excel/combined_long.csv')\n",
    "print(\"Saved to long CSV: data/excel/combined_long.csv\")\n",
    "\n",
    "# Save to CSV (wide format)\n",
    "tri.triangle_to_wide_csv(combined, 'data/excel/combined_wide.csv')\n",
    "print(\"Saved to wide CSV: data/excel/combined_wide.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to JSON\n",
    "tri.triangle_to_json(combined, 'data/excel/combined.json')\n",
    "print(\"Saved to JSON: data/excel/combined.json\")\n",
    "\n",
    "# Peek at the JSON structure\n",
    "import json\n",
    "with open('data/excel/combined.json', 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "    print(json.dumps(json_data, indent=2, default=str)[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to binary trib format (most efficient)\n",
    "tri.triangle_to_binary(combined, 'data/excel/combined.trib')\n",
    "print(\"Saved to binary trib: data/excel/combined.trib\")\n",
    "\n",
    "# Compare file sizes\n",
    "import os\n",
    "sizes = {\n",
    "    'CSV (long)': os.path.getsize('data/excel/combined_long.csv'),\n",
    "    'CSV (wide)': os.path.getsize('data/excel/combined_wide.csv'),\n",
    "    'JSON': os.path.getsize('data/excel/combined.json'),\n",
    "    'Trib (binary)': os.path.getsize('data/excel/combined.trib')\n",
    "}\n",
    "\n",
    "print(\"\\nFile size comparison:\")\n",
    "for format_name, size in sizes.items():\n",
    "    print(f\"  {format_name}: {size:,} bytes\")\n",
    "\n",
    "print(f\"\\nBinary format is {sizes['JSON'] / sizes['Trib (binary)']:.1f}x smaller than JSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've covered:\n",
    "\n",
    "1. **Data Format Types**: Long, wide, and array formats each have their use cases\n",
    "2. **Ingestion Methods**: Different functions for each format\n",
    "3. **Column Mapping**: Aligning external column names with Bermuda conventions\n",
    "4. **Multi-Slice Triangles**: Combining triangles from different sources\n",
    "5. **Export Options**: CSV, JSON, and binary formats with different trade-offs\n",
    "\n",
    "The binary trib format is Ledger's proprietary format that:\n",
    "- Saves space (typically 5-10x smaller than JSON)\n",
    "- Loads faster (no parsing overhead)\n",
    "- Preserves all metadata and structure perfectly\n",
    "- Works seamlessly across Bermuda versions\n",
    "\n",
    "### Answer Key for Exercises\n",
    "\n",
    "**Exercise 1:**\n",
    "```python\n",
    "ca_triangle_csv = tri.wide_csv_to_triangle('data/excel/ca_wide.csv')\n",
    "```\n",
    "\n",
    "**Exercise 2:**\n",
    "```python\n",
    "pa_csv_df = pd.read_csv('data/excel/pa_array.csv')\n",
    "pa_triangle_csv = tri.array_data_frame_to_triangle(\n",
    "    pa_csv_df,\n",
    "    field='paid_loss',\n",
    "    period_resolution=12,\n",
    "    eval_resolution=12\n",
    ")\n",
    "```\n",
    "\n",
    "**Exercise 3:**\n",
    "```python\n",
    "multi_triangle = tri.array_triangle_builder(\n",
    "    dfs=[paid_array, reported_array],\n",
    "    fields=['paid_loss', 'reported_loss'],\n",
    "    period_resolution=12,\n",
    "    eval_resolution=12\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
